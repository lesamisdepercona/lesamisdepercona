+++
title = "MongoDB 5.0 : Collecte de séries chronologiques"
description = "Definir le Collecte de séries chronologiques avec un exemple type en MongoDB selon les requêtes habituelles"
author = "Francis"
date = 2022-02-01
tags = ['MongoDB']
Categories = ["Article de Percona"]
featured_image = "thumbnail/2022/article03.jpg"
images = ["thumbnail/2022/article03.jpg"]
slug = "MongoDB-5.0-collecte-de-series-chronologiques"
+++

![thumbnail](/thumbnail/2022/article03.jpg)

Dans un précédent article, j'ai testé [une nouvelle fonctionnalité de MongoDB 5.0 : le resharding ](https://www.percona.com/blog/resharding-in-mongodb-5-0/). Aujourd'hui, je découvre une autre nouveauté : les collections Time Series.

La collection Time Series est une nouvelle fonctionnalité étonnante disponible dans MongoDB 5.0. D'après les premiers tests que j'ai effectués, la prise en charge des séries chronologiques offre des performances comparables à l'utilisation d'index sur des collections régulières, mais économise beaucoup d'espace disque et mémoire. Les pipelines d'agrégation, qui sont des requêtes courantes que vous pouvez exécuter sur des données de séries chronologiques, peuvent obtenir encore plus d'avantages.

Commençons les tests.

## Qu'est-ce qu'une base de données de séries chronologiques ?

De manière générale, une base de données Time Series est une base de données spécialisée conçue pour stocker efficacement les données générées à partir d'un flux continu de valeurs associées à un horodatage. Le cas d'utilisation typique est celui où vous avez besoin de stocker des données provenant d'un équipement sensoriel qui transmet des points de données à intervalles fixes, mais qui sont désormais utilisées pour prendre en charge une gamme d'applications beaucoup plus large.

Les cas typiques sont :

- Données IoT
- Surveillance des services Web, des applications et de l'infrastructure
- Prévision des ventes
- Compréhension tendances financières
- Traitement des données de la voiture autonome ou d'autres appareils physiques

Une base de données spécialisée dans les séries chronologiques utilise des algorithmes de compression pour minimiser l'espace requis et fournit également des chemins d'accès pour creuser plus efficacement dans les données. Cela améliore les performances de récupération des données en fonction des filtres de plage de temps et de l'agrégation des données. Ils sont plus efficaces que l'utilisation d'une base de données relationnelle commune.

Habituellement, les valeurs d'une série chronologique ne doivent pas changer une fois enregistrées, elles sont définies comme INSERT uniquement, également appelées points de données immuables. Une fois les données stockées, l'opération de mise à jour est vraiment rare.

Une autre caractéristique des séries chronologiques est que chaque élément doit avoir une valeur unique (une seule température, un cours de bourse, etc.).

Les bases de données de séries chronologiques populaires sont [InfluxDB ](https://www.influxdata.com/), [Prometheus ](https://prometheus.io/), [Graphite ](https://github.com/graphite-project/graphite-web). Il y en a aussi beaucoup d'autres. [VictoriaMetrics ](https://victoriametrics.com/)en particulier est un fork populaire de Prometheus et est utilisé dans notre logiciel [Percona Monitoring and Management ](https://www.percona.com/software/database-tools/percona-monitoring-and-management)Percona .

## Les nouvelles collections de séries chronologiques dans MongoDB 5.0

MongoDB, ainsi que les bases de données relationnelles, est largement utilisé depuis des années pour stocker les données de température des capteurs, les cours des actions et tout autre type de données immuables dans le temps. MongoDB version 5.0 promet que cela peut être fait plus efficacement, alors regardons comment cela fonctionne.

Une collection Time Series apparaît comme une collection normale et les opérations que vous pouvez effectuer sont exactement les mêmes : insérer, mettre à jour, rechercher, supprimer, agréger. La principale différence est derrière le rideau. MongoDB stocke les données dans un format de stockage optimisé lors de l'insertion. Par rapport à une collection normale, une série chronologique est plus petite et offre une plus grande efficacité des requêtes.

MongoDB traite les collections Time Series comme des vues inscriptibles non matérialisées. Les données sont stockées plus efficacement, économisant de l'espace disque, et un index interne créé automatiquement classe les données dans le temps. Par défaut, les données sont compressées à l'aide de l'algorithme **zstd** au lieu de **snappy** . La nouvelle compression offre un rapport plus élevé, moins d'exigences en matière de CPU et convient bien aux données de séries chronologiques où il y a peu de variations d'un document à l'autre. Vous pouvez éventuellement changer l'algorithme de compression, mais ce n'est pas vraiment recommandé.

Une collection de séries chronologiques n'est pas implicitement créée lorsque vous insérez un document, comme les collections normales. Vous devez le créer explicitement.

Faisons quelques tests.

## Créer une collection de séries chronologiques pour stocker les cours des actions

Nous devons utiliser la méthode createCollection(), en fournissant certains paramètres.
```
[direct: mongos] timeseries> db.createCollection( 
"stockPrice1week", { 
  timeseries: { 
    timeField: "timestamp", 
    metaField: "metadata", 
    granularity: "minutes" 
  }, 
  expireAfterSeconds: 604800   
  }
)
{ ok: 1 }
```
Le nom de la collection est **stockPrice1week** et le seul paramètre requis est **timeField** . Les autres paramètres sont facultatifs.

*timeField* : le nom du champ où la date est stockée. Celle-ci sera automatiquement indexée et utilisée pour récupérer les données.

*metaField* : le champ contenant les métadonnées. Il peut s'agir d'une simple valeur scalaire ou d'un objet JSON plus complexe. C'est facultatif. Ce ne peut pas être le *\_id* ou le même que le *timeField .* Par exemple, les métadonnées d'un capteur de température peuvent être le code du capteur, le type, l'emplacement, etc.

*granularité* : les valeurs possibles sont *secondes* , *minutes* et *heures* . S'il n'est pas défini, la valeur par défaut est *seconds* . Si vous spécifiez la correspondance la plus proche entre deux valeurs consécutives, cela aidera MongoDB à stocker les données plus efficacement et à améliorer les performances de la requête.

*expireAfterSeconds* : vous pouvez supprimer automatiquement les documents après le délai spécifié, de la même manière que l'index TTL. S'il n'est pas spécifié, les documents n'expireront pas.

Insérons quelques données aléatoires pour trois actions : Apple, Orange et Banana. Les données sont collecté une fois par minute.
```
[direct: mongos] timeseries> var stockPriceDate = ISODate("2021-10-13T00:00:00.000Z")

[direct: mongos] timeseries> var priceApple = 100

[direct: mongos] timeseries> var priceOrange = 50

[direct: mongos] timeseries> var priceBanana = 80

[direct: mongos] timeseries> for (i = 1; i < 100000; i++) { 
  priceApple = priceApple + Math.random(); 
  priceOrange = priceOrange + Math.random(); 
  priceBanana = priceBanana + Math.random(); 
  db.stockPrice1week.insert({ "timestamp": stockPriceDate, "metadata": { "stockName": "Apple", "currency": "Dollar" }, "stockPrice": priceApple }); 
  db.stockPrice1week.insert({ "timestamp": stockPriceDate, "metadata": { "stockName": "Orange", "currency": "Dollar" }, "stockPrice": priceOrange }); 
  db.stockPrice1week.insert({ "timestamp": stockPriceDate, "metadata": { "stockName": "Banana", "currency": "Euro" }, "stockPrice": priceBanana }); 
  stockPriceDate = new Date(stockPriceDate.getTime() + 1000 * 60); 
}
```
Nous pouvons interroger pour vérifier les documents insérés :
```
[direct: mongos] timeseries> db.stockPrice1week.find().limit(3)
[
  {
    _id: ObjectId("6166df318f32e5d3ed304fc5"),
    timestamp: ISODate("2021-10-13T00:00:00.000Z"),
    metadata: { stockName: 'Apple', currency: 'Dollar' },
    stockPrice: 100.6547271930824
  }, 
  {
    _id: ObjectId("6166df318f32e5d3ed304fc6"),
    timestamp: ISODate("2021-10-13T00:00:00.000Z"),
    metadata: { stockName: 'Orange', currency: 'Dollar' },
    stockPrice: 50.51709117468818
  },  
  {
    _id: ObjectId("6166df318f32e5d3ed304fc7"),
    timestamp: ISODate("2021-10-13T00:00:00.000Z"),
    metadata: { stockName: 'Banana', currency: 'Euro' },
    stockPrice: 80.17611551979255
  }
]
```
## Vérifiez la taille de la collection

Maintenant, créons une collection régulière ayant exactement les mêmes données.
```
[direct: mongos] timeseries> db.stockPrice1week.find().forEach(function (doc) {
  db.stockPrice1week_regular.insertOne(doc);
})
```
Vérifions la taille totale des deux collections.
```
[direct: mongos] timeseries> db.stockPrice1week.stats().totalSize
5357568
[direct: mongos] timeseries> db.stockPrice1week_regular.stats().totalSize
21934080
```
Comme prévu, la collection Time Series est quatre fois plus petite que la collection régulière. De plus, considérez que la collection régulière n'a pas d'index secondaire pour le moment.

## Requëtes des collections

Exécutons une requête simple pour connaître les valeurs de stock pour un horodatage spécifique. Nous testons la requête sur les deux collections.
```
[direct: mongos] timeseries> db.stockPrice1week.find( { "timestamp": ISODate("2021-10-23T12:00:00.000Z") } )
[
  { 
    _id: ObjectId("6166dfc68f32e5d3ed3100f5"),
    timestamp: ISODate("2021-10-23T12:00:00.000Z"),
    metadata: { stockName: 'Apple', currency: 'Dollar' },
    stockPrice: 7636.864548363888
  },
  {
    _id: ObjectId("6166dfc68f32e5d3ed3100f6"),
    timestamp: ISODate("2021-10-23T12:00:00.000Z"),
    metadata: { stockName: 'Orange', currency: 'Dollar' },
    stockPrice: 7607.03756525094
  },
  {
    _id: ObjectId("6166dfc68f32e5d3ed3100f7"),
    timestamp: ISODate("2021-10-23T12:00:00.000Z"),
    metadata: { stockName: 'Banana', currency: 'Euro' },
    stockPrice: 7614.360031277444  
  }
]
[direct: mongos] timeseries> db.stockPrice1week_regular.find( { "timestamp": ISODate("2021-10-23T12:00:00.000Z") } )
[
  {
    _id: ObjectId("6166dfc68f32e5d3ed3100f5"),
    timestamp: ISODate("2021-10-23T12:00:00.000Z"),
    metadata: { stockName: 'Apple', currency: 'Dollar' },
    stockPrice: 7636.864548363888
  }, 
  {
    _id: ObjectId("6166dfc68f32e5d3ed3100f6"),
    timestamp: ISODate("2021-10-23T12:00:00.000Z"),
    metadata: { stockName: 'Orange', currency: 'Dollar' },
    stockPrice: 7607.03756525094
  },
  {
    _id: ObjectId("6166dfc68f32e5d3ed3100f7"),
    timestamp: ISODate("2021-10-23T12:00:00.000Z"),
    metadata: { stockName: 'Banana', currency: 'Euro' },
    stockPrice: 7614.360031277444
  }
]
```
Nous avons le même résultat, mais ce qui est important ici, c'est de regarder l' *explain( )* pour voir le plan d'exécution. Voici explain( ) de la collection régulière.
```
[direct: mongos] timeseries> db.stockPrice1week_regular.find( { "timestamp": ISODate("2021-10-23T12:00:00.000Z") } ).explain("executionStats")
{
...
winningPlan: {
  stage: 'COLLSCAN',
  filter: {
    timestamp: { '$eq': ISODate("2021-10-23T12:00:00.000Z") }
  },
  direction: 'forward'
...
...
executionSuccess: true,
nReturned: 3,
executionTimeMillis: 200,
totalKeysExamined: 0,
totalDocsExamined: 299997,
...
...
```
Nous n'avons créé aucun index secondaire, donc le plan gagnant est un COLLSCAN, tous les documents doivent être examinés. La requête prend 200 millisecondes.

Ce qui suit est explain() de la collection Time Series à la place.
```
[direct: mongos] timeseries> db.stockPrice1week.find( { "timestamp": ISODate("2021-10-23T12:00:00.000Z") } ).explain("executionStats")
{
...
...
executionStats: {
  executionSuccess: true,
  nReturned: 3,
  executionTimeMillis: 2,
  totalKeysExamined: 0,
  totalDocsExamined: 8,
  executionStages: {
  stage: 'COLLSCAN',
    filter: {
      '$and': [
        {
          _id: { '$lte': ObjectId("6173f940ffffffffffffffff") }
        },
        {
          _id: { '$gte': ObjectId("6172a7c00000000000000000") }
        },
      {
      'control.max.timestamp': {
        '$_internalExprGte': ISODate("2021-10-23T12:00:00.000Z")
      }
    },
    {
      'control.min.timestamp': {
        '$_internalExprLte': ISODate("2021-10-23T12:00:00.000Z")
      }
    }
  ]
},
...
...
```
Étonnamment, il s'agit d'un COLLSCAN, mais avec des numéros différents. Le nombre de documents examinés n'est plus que de huit et le temps d'exécution est de deux millisecondes.

Comme déjà mentionné, la série chronologique est une vue non matérialisée. Il fonctionne comme une couche d'abstraction. Les données réelles sont stockées dans une autre collection système ( *system.buckets.stockPrice1week* ) où les documents sont enregistrés dans un format légèrement différent. Ce n'est pas le but de cet article de creuser dans les internes, gardez simplement à l'esprit que les différents formats de stockage permettent à mongod de récupérer seulement quelques seaux de données au lieu de tout lire, même s'il est signalé comme COLLSCAN. C'est incroyable.

## Que se passe-t-il si je crée un index sur la collection régulière ?

Allons essayer.
```
[direct: mongos] timeseries> db.stockPrice1week_regular.createIndex( { "timestamp": 1 } )
timestamp_1
[direct: mongos] timeseries> db.stockPrice1week_regular.getIndexes()
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  { v: 2, key: { timestamp: 1 }, name: 'timestamp_1' }
]
[direct: mongos] timeseries> db.stockPrice1week_regular.find({"timestamp": ISODate("2021-10-23T12:00:00.000Z")}).explain("executionStats")
{
...
...
winningPlan: {
  stage: 'FETCH',
  inputStage: {
  stage: 'IXSCAN',
  keyPattern: { timestamp: 1 },
  indexName: 'timestamp_1',
...
...
executionStats: {
  nReturned: 3,
  executionTimeMillis: 2,
  totalKeysExamined: 3,
  totalDocsExamined: 3,
...
```
Maintenant, le plan gagnant est un IXSCAN, le nouvel index est utilisé. Seulement trois clés examinées, trois documents examinés et trois documents retournés. La requête prend deux millisecondes.

Ainsi, il est aussi rapide que la collection Time Series. Il n'y a pas une si grande différence; l'ordre de grandeur est le même.

Notez également que les mêmes performances se font au prix d'une plus grande collection à la fin car nous avons créé un index secondaire.
```
[direct: mongos] timeseries> db.stockPrice1week_regular.stats().totalSize
25251840
[direct: mongos] timeseries> db.stockPrice1week.stats().totalSize
5357568
```
Pour obtenir un temps d'exécution comparable, la collection régulière est maintenant cinq fois plus grande que la série chronologique.

## Une requête avec un filtre de plage de temps

Testons une requête différente à la recherche d'une plage d'horodatages. Voici les sorties de explain() 
```
[direct: mongos] timeseries> db.stockPrice1week_regular.find( { "timestamp": { $gte: ISODate("2021-10-20T00:00:00Z"), $lt: ISODate("2021-10-20T23:59:59Z") } } ).explain("executionStats")
{
...
winningPlan: {
  stage: 'FETCH',
  inputStage: {
    stage: 'IXSCAN',
    keyPattern: { timestamp: 1 },
...
executionStats: {
  nReturned: 4320,
  executionTimeMillis: 7,
  totalKeysExamined: 4320,
  totalDocsExamined: 4320,
...
```
```
[direct: mongos] timeseries> db.stockPrice1week.find( { "timestamp": { $gte: ISODate("2021-10-20T00:00:00Z"), $lt: ISODate("2021-10-20T23:59:59Z") } } ).explain("executionStats")
{
...
...
winningPlan: {
  stage: 'COLLSCAN',
  filter: {
    '$and': [
    {
      _id: { '$lt': ObjectId("6170ad7f0000000000000000") }
    },
    {
      _id: { '$gte': ObjectId("616e0a800000000000000000") }
    },
    {
      'control.max.timestamp': {
        '$_internalExprGte': ISODate("2021-10-20T00:00:00.000Z")
      }
    },
    {
      'control.min.timestamp': {
        '$_internalExprLt': ISODate("2021-10-20T23:59:59.000Z")
      }
    }
  ]
},
...
...
executionStats: {
  executionSuccess: true,
  nReturned: 6,
  executionTimeMillis: 6,
  totalKeysExamined: 0,
  totalDocsExamined: 11,
...
```
La même chose que précédente. Le temps d'exécution est fondamentalement le même pour les deux requêtes. Le principal problème reste la taille de la collection régulière qui est nettement plus importante.

Seuls six documents sont apparemment renvoyés par la série chronologique, mais ce n'est pas le cas. Si vous exécutez la requête pour de vrai, vous obtiendrez 4320 documents. Les six documents mentionnés par explain() font référence aux documents qui doivent être renvoyés par la collection réelle sous la vue non matérialisée.

## Test d'agrégation

Sur nos données de séries chronologiques, nous aimerions faire une agrégation. Il s'agit d'une tâche typique : calculer des moyennes sur une période, trouver des valeurs minimales et maximales et d'autres types de statistiques.

Supposons que nous ayons besoin de calculer quotidiennement le cours moyen des actions. Nous pouvons utiliser le pipeline d’agrégation ci-après par exemple :
```
db.stockPrice1week.aggregate([
{
  $project: {
    date: {
      $dateToParts: { date: "$timestamp" }
    },
    stockPrice: 1
  }
},
{
  $group: {
    _id: {
      date: {
        year: "$date.year",
        month: "$date.month",
        day: "$date.day"
      }
    },
    avgPrice: { $avg: "$stockPrice" }
  }
}
])
[
{
_id: { date: { year: 2021, month: 12, day: 4 } },
avgPrice: 37939.782043249594
},
{
_id: { date: { year: 2021, month: 11, day: 22 } },
avgPrice: 29289.700949196136
},
{
_id: { date: { year: 2021, month: 10, day: 27 } },
avgPrice: 10531.347070537977
},
...
...
```
Comme d'habitude, examinons explain() de l'agrégat par rapport aux deux collections, en nous concentrant uniquement sur le temps d'exécution et les documents examinés.
```
[direct: mongos] timeseries> db.stockPrice1week.explain("executionStats").aggregate([ { $project: { date: { $dateToParts: { date: "$timestamp" } }, stockPrice: 1 } }, { $group: { _id: { date: { year: "$date.year", month: "$date.month", day: "$date.day" } }, avgPrice: { $avg: "$stockPrice" } } }])
{
...
executionStats: {
  executionSuccess: true,
  nReturned: 300,
  executionTimeMillis: 615,
  totalKeysExamined: 0,
  totalDocsExamined: 300,
  executionStages: {
  stage: 'COLLSCAN',
...
```
```
[direct: mongos] timeseries> db.stockPrice1week_regular.explain("executionStats").aggregate([ { $project: { date: { $dateToParts: { date: "$timestamp" } }, stockPrice: 1 } }, { $group: { _id: { date: { year: "$date.year", month: "$date.month", day: "$date.day" } }, avgPrice: { $avg: "$stockPrice" } } }])
{
...
executionStats: {
  executionSuccess: true,
  nReturned: 299997,
  executionTimeMillis: 1022,
  totalKeysExamined: 0,
  totalDocsExamined: 299997,
  executionStages: {
    stage: 'PROJECTION_DEFAULT',
...
```
Le pipeline d'agrégation s'exécute 40 % plus rapidement avec la collection Time Series. Cela devrait être d'autant plus pertinent que la collection est grande.

## Conclusion

MongoDB 5.0 est une nouvelle version intéressante de la base de données documentaire la plus populaire, et de nouvelles fonctionnalités telles que les collections Time Series et le repartitionnement sont incroyables.

Quoi qu'il en soit, en raison de nombreux changements apportés au cœur de WiredTiger et du serveur principal introduit pour faciliter les nouvelles fonctionnalités, MongoDB 5.0.x est toujours instable. Nous ne recommandons pas de l'utiliser pour les environnements de production.

Consultez la documentation de [Percona Server pour MongoDB 5.0.3-2 (Release Candidate) ](https://www.percona.com/doc/percona-server-for-mongodb/5.0/release_notes/5.0.3-2.html).

Source : [Percona Blog](https://www.percona.com/blog/mongodb-5-0-time-series-collections/)
